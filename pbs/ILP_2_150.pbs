#PBS -N ILP_2_150 
#PBS -j oe
#PBS -o ILP_log_2_150.out
#PBS -m abe                            
#PBS -A GT-saluru8-CODA20         # account to which job is charged, ex: GT-gburdell3
#PBS -l nodes=1:ppn=1          # number of nodes and cores per node required
#PBS -l pmem=300gb                # memory per core
#PBS -l walltime=96:00:00

# change according to the job submission requirement of your cluster

cd $PBS_O_WORKDIR

project_dir=/storage/coda1/p-saluru8/0/ntavakoli6/hg
software_dir=/storage/coda1/p-saluru8/0/ntavakoli6/software
DATA=/storage/coda1/p-saluru8/0/ntavakoli6/hg/data

cd ${project_dir}
bcftools=/storage/coda1/p-saluru8/0/ntavakoli6/software/bcftools/bcftools
vcftools=/storage/coda1/p-saluru8/0/ntavakoli6/software/vcftools-0.1.16/bin/vcftools
tabix=/storage/coda1/p-saluru8/0/ntavakoli6/software/tabix/tabix

cd ${DATA}

module load anaconda3 gurobi

export PYTHONPATH=$GUROBI_HOME/lib/python3.8_utf32:$PYTHONPATH

echo "start running"
python3 ILP_chr22_hg.py --hap col4_chr22_haplotypes_frq_all_2.txt --k 2504 --n 1064080 --alpha 150 --delta 2
